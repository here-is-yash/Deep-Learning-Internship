{"cells":[{"cell_type":"code","execution_count":null,"id":"413bba5c-226c-49ec-bb8d-e89bbc779066","metadata":{"id":"413bba5c-226c-49ec-bb8d-e89bbc779066","outputId":"0caee255-3e4e-41e0-8afd-d3741a25c2f7"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\BHARATH\\anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\BHARATH\\anaconda3\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n","  warn(f\"Failed to load image Python extension: {e}\")\n"]}],"source":["# Importing the libraries \n","\n","import torchvision\n","import torch\n","import torchvision.transforms as transforms\n","import os\n","import matplotlib.pyplot as plt\n","import numpy\n","import torch.nn as nn\n","import torch.optim as optim\n","from random import randint\n","import utils\n","import time"]},{"cell_type":"code","execution_count":null,"id":"7a7767bf-eb04-4c59-ab2f-8a0bf4f7b114","metadata":{"id":"7a7767bf-eb04-4c59-ab2f-8a0bf4f7b114","outputId":"d54ce560-f6db-4cc9-a775-b242cddebe68"},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n"]}],"source":["#device= torch.device(\"cuda\")       \n","device= torch.device(\"cpu\")        # here we are informing the PyTorch to use CPU only and not GPU on availability\n","print(device)"]},{"cell_type":"code","execution_count":null,"id":"bbd37f71-b586-4efc-9d2f-f67cfd25a98b","metadata":{"id":"bbd37f71-b586-4efc-9d2f-f67cfd25a98b"},"outputs":[],"source":["train_path='./Dataset/train'       # Path of dataset are are given \n","test_path='./Dataset/test'"]},{"cell_type":"code","execution_count":null,"id":"ee522333-7a06-40b2-bff8-a954dba3c33d","metadata":{"id":"ee522333-7a06-40b2-bff8-a954dba3c33d"},"outputs":[],"source":["classes=os.listdir('./Dataset/test')     \n","len_class=len(classes)                # It shows the number of classes being differentiated"]},{"cell_type":"code","execution_count":null,"id":"77431fd1-c11c-44d5-87e9-86ca4216d665","metadata":{"id":"77431fd1-c11c-44d5-87e9-86ca4216d665","outputId":"b0adf55c-0ae8-4d12-ac74-f5dcb83c9d86"},"outputs":[{"data":{"text/plain":["7"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["len_class"]},{"cell_type":"code","execution_count":null,"id":"30de481a-1d97-4603-af2f-a7cd696a7c88","metadata":{"id":"30de481a-1d97-4603-af2f-a7cd696a7c88"},"outputs":[],"source":["train_transform=transforms.Compose([transforms.Resize((48,48)),transforms.ToTensor()])      # Through compose we are doing resizing and converting ...\n","test_transform=transforms.Compose([transforms.Resize((48,48)),transforms.ToTensor()])       #...images data to tensor"]},{"cell_type":"code","execution_count":null,"id":"2f4d32c2-5ead-49b1-95d1-f6731504fffb","metadata":{"id":"2f4d32c2-5ead-49b1-95d1-f6731504fffb"},"outputs":[],"source":["train_data=torchvision.datasets.ImageFolder(root=train_path,transform=train_transform)      #ImageFolder find path given(root)...\n","test_data=torchvision.datasets.ImageFolder(root=test_path,transform=test_transform)         #...Transform, transforms the image and returns a transformed version\n","                                                                                            # WITH LABELS"]},{"cell_type":"code","execution_count":null,"id":"207d6a84-ecc3-4e18-8c1e-44e69e284ea5","metadata":{"id":"207d6a84-ecc3-4e18-8c1e-44e69e284ea5"},"outputs":[],"source":["train_load=torch.utils.data.DataLoader(train_data,batch_size=32,shuffle=True)               #DataLoader of torch returns the batch given the transformations...\n","test_load=torch.utils.data.DataLoader(test_data,batch_size=32,shuffle=False)                #... and data directory that we set with the above Transform and ImageFolder class."]},{"cell_type":"code","execution_count":null,"id":"f3844eb1-ba58-4cc8-84df-54d34da1a5b3","metadata":{"id":"f3844eb1-ba58-4cc8-84df-54d34da1a5b3"},"outputs":[],"source":["class multi_layer_net(nn.Module):                                                           # here we are definiing the model \n","\n","    def __init__(self):\n","        super(multi_layer_net , self).__init__()\n","        \n","        self.layer1 = nn.Linear(  48*48*3 , 48*48*3, bias=False  )                          #1st layer takes the 6912 as input and output of 6912 at output(hidden size)\n","        self.layer2 = nn.Linear(  48*48*3 ,48*48*3 , bias=False  )                          #2nd layer takes the 6912 as input and output of 6912 at output(hidden size)\n","        self.layer3 = nn.Linear(  48*48*3 , 7  , bias=False  )                              #3rd layer takes the 6912 as input and output of 7 at output\n","        \n","        self.flat =nn.Flatten()                                                             #Flattening the tensor\n","        \n","        self.batch1= nn.BatchNorm1d(48*48*3)                                                #We normalize the batch, instead of a explicit formula, direct function is used\n","        \n","    def forward(self, x):\n","        x  = self.flat(x)                                                                   # we take it through layers\n","        y       = self.layer1(x)\n","        y_hat   = torch.relu(y)\n","        y_hat   = self.batch1(y_hat)\n","        z       = self.layer1(y_hat)\n","        z_hat   = torch.relu(z)\n","        scores  = self.layer2(z_hat)\n","        \n","        return scores"]},{"cell_type":"code","execution_count":null,"id":"b81d2003-ab29-43bb-a71c-0426a9127132","metadata":{"id":"b81d2003-ab29-43bb-a71c-0426a9127132","outputId":"aa60d7f9-6d5f-4815-f21f-800de8b4a7b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["multi_layer_net(\n","  (layer1): Linear(in_features=6912, out_features=6912, bias=False)\n","  (layer2): Linear(in_features=6912, out_features=6912, bias=False)\n","  (layer3): Linear(in_features=6912, out_features=7, bias=False)\n","  (flat): Flatten(start_dim=1, end_dim=-1)\n","  (batch1): BatchNorm1d(6912, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",")\n","There are 95613696 (95.61 million) parameters in this neural network\n"]}],"source":["net=multi_layer_net()                                                                       # Apply the net and verify the output\n","\n","print(net)\n","utils.display_num_param(net)"]},{"cell_type":"code","execution_count":null,"id":"fa88715f-11ad-4585-8c17-a3311172bf44","metadata":{"id":"fa88715f-11ad-4585-8c17-a3311172bf44"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()                                                          # we check the cross entropy loss\n","\n","optimizer=torch.optim.SGD( net.parameters() , lr=0.01 )                                    # defining the leatrning rate and loss is minimized with stochastic gradient descent\n","\n","bs=20                                                                                      # batch size"]},{"cell_type":"code","execution_count":null,"id":"51a9199e-6018-4cd7-8524-7f55a322a732","metadata":{"id":"51a9199e-6018-4cd7-8524-7f55a322a732"},"outputs":[],"source":["def eval_on_test_set():                                                                    # for test data \n","\n","    running_error=0\n","    num_batches=0\n","\n","    for i , (images,labels) in enumerate(train_load):\n","\n","        if torch.cuda.is_available():\n","            images=Variable(images.cuda())\n","            labels=Variable(labels.cuda())\n","            \n","        scores=net( images ) \n","\n","        error = utils.get_error( scores , labels)\n","\n","        running_error += error.item()\n","\n","        num_batches+=1\n","\n","\n","    total_error = running_error/num_batches\n","    print( 'test error  = ', total_error*100 ,'percent')\n","    \n","    return total_error*100"]},{"cell_type":"code","execution_count":null,"id":"fbfbe009-0c19-45e8-b1f2-294f546fecc9","metadata":{"id":"fbfbe009-0c19-45e8-b1f2-294f546fecc9","outputId":"1009ddbf-f905-4844-c673-e49e77f14204"},"outputs":[{"name":"stdout","output_type":"stream","text":[" \n","epoch= 0 \t time= 896.3249180316925 \t loss= 1.8006227899234917 \t error= 66.54092427882426 percent\n","test error  =  66.2103285104501 percent\n"," \n","epoch= 5 \t time= 5597.830278158188 \t loss= 1.583921284744628 \t error= 60.929148108231736 percent\n","test error  =  61.34117483296214 percent\n"," \n","epoch= 10 \t time= 10572.129238128662 \t loss= 1.6009109273785207 \t error= 62.5995267273854 percent\n","test error  =  62.98580178306469 percent\n"]}],"source":["start = time.time()                                                                           # we train the network\n","min_loss=[]\n","for epoch in range(200):\n","    \n","    running_loss=0\n","    running_error=0\n","    num_batches=0\n","    \n","    net.train()\n","    \n","    for i , (images,labels) in enumerate(train_load):\n","\n","        if torch.cuda.is_available():\n","            images=Variable(images.cuda())\n","            labels=Variable(labels.cuda())\n","        # Set the gradients to zeros\n","        optimizer.zero_grad()\n","        \n","        scores=net( images )                 #apply the net on batch\n","\n","        loss =  criterion( scores , labels)  #check loss for a batch\n","        \n","        loss.backward()                      # backward pass to find dL/dU, dL/dV and dL/dW \n","\n","        optimizer.step()                     # do one step of stochastic gradient descent calculation\n","        \n","        \n","        # compute some stats\n","        \n","        running_loss += loss.detach().item()\n","               \n","        error = utils.get_error( scores.detach() , labels)\n","        running_error += error.item()\n","        \n","        num_batches+=1\n","    \n","    \n","    # once the epoch is finished we divide the \"running quantities\"\n","    # by the number of batches\n","    \n","    total_loss = running_loss/num_batches\n","    total_error = running_error/num_batches\n","    elapsed_time = time.time() - start\n","    \n","    # every 10 epoch we display the stats \n","    # and compute the error rate on the test set  \n","    \n","    if epoch % 5 == 0 : \n","    \n","        print(' ')\n","        \n","        print('epoch=',epoch, '\\t time=', elapsed_time,\n","              '\\t loss=', total_loss , '\\t error=', total_error*100 ,'percent')\n","        \n","        test_error=eval_on_test_set()\n","        \n","        min_loss.append(test_error)\n","        \n","    if epoch == 200:\n","        mini=min(min_loss)\n","        \n","        print(\"\\nTestAccuracy:\"+str(100-mini))\n","    "]},{"cell_type":"code","execution_count":null,"id":"560f8102-0f79-42e3-825c-19331f5c2e37","metadata":{"id":"560f8102-0f79-42e3-825c-19331f5c2e37"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"name":"MLP_1.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}